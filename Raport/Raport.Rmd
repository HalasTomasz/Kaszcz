---
title: "Komputerowa analiza szeregów czasowych - raport 1"
author: "Szymon Malec, Tomasz Hałas"
output:
  pdf_document: 
    extra_dependencies: ["polski", "mathtools", "amsthm", "amssymb", "icomma", "upgreek", "xfrac", "scrextend", "float", "tabularx", "hyperref", "caption", "enumitem"]
fontsize: 12pt
---

\renewcommand{\figurename}{Wykres}
\renewcommand{\tablename}{Tablica}
\raggedbottom

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE, fig.pos = "H", dev.args=list(encoding="CP1257.enc"))
```

```{r}
library(ggplot2)
library(dplyr)
library(zeallot)
library(tidyr)
library(knitr)
library(reshape2)
library(cowplot)
library(latex2exp)

regression <- function(X, Y){
    r <- cor(X, Y, use="pairwise.complete.obs")
    Sx <- sd(X)
    Sy <- sd(Y)
    a <- r * Sy / Sx
    b <- mean(Y) - a * mean(X)
    return(c(a, b))
}

data <- read.csv('data/data.csv')
data2015 <- data %>% filter(year == 2015)
data_filtered <- data2015 %>% filter(!is.na(schooling) & !is.na(life_expectancy))

X <- data_filtered$schooling
Y <- data_filtered$life_expectancy
c(a, b) %<-% regression(X, Y)
E <- Y - a*X - b
```




\section{Wstęp}
<!-- Akapit - 6 spacji -->
|      Celem raportu jest zbadanie liniowej korelacji pomiędzy edukacją, a długością życia. Wykorzystane do tego zostaną dane dostępne pod [$\color{blue}{\text{linkiem}}$](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who?fbclid=IwAR2HtwUPyioM4tHmuae7B2owTUB8q3XlmpP12LbTM9NYDsi4qtaWGOYoNDE). Przeprowadzimy dokładną analizę zależności między dwoma zmiennymi oraz zastosujemy odpowiednie metody, by dopasować prostą regresji do danych, po czym zweryfikujemy czy dopasowanie można uznać prawidłowe. Otrzymane wyniki wykorzystane zostaną do przeprowadzenia predykcji długości życia w zależności od czasu edukacji.





\section{Opis danych}
|      Nasze dane składają się z poszczególnych kolumn:
\begin{itemize}
  \item country -- kolumna zawiera informacje o kraju, z jakiego pochodza dane;
  \item year -- rok w którym uzyskano dane;
  \item status -- informacja o aktualnym statusie rozwoju kraju;
  \item life\_expectancy -- przewidywana długośc życia mieszkańców w danym kraju;
  \item adult\_mortality -- liczba śmierci osób wieku 15--60 lat na 1000 osób populacji;
  \item infant\_deaths -- liczba śmierci noworodków na 1000 osób populacji;
  \item alcohol -- ilośc wypijanych litrów alkokolów na każdeego mieszkańca powyżej 15 roku życia;
  \item percentage\_expenditure  -- wydatki na zdrowie wyliczane wstosunku do produktu krajowego brutto na mieszkańca kraju;
  \item hepatitis\_B -- stopień uodpornienia na wirusowe zapalenie wątroby typu B wśród dzieci w wieku 1 lat;
  \item measles -- liczba zgłoszonych przypadków na 1000 osób populacji;
  \item BMI -- średni wskaźnik masy ciała dla całej populacji;
  \item under\_five\_deaths -- liczba śmierci dzieci ponizej 5 lat na 1000 osób populajcji;
  \item polio -- stopień uodpornienia na wirusa Polio wśród 1--latków;
  \item total\_expenditure -- wydatki sektora publicznego na zdrowie jako odsetek całkowitych wydatków;
  \item diphtheria -- stopień uodpornienia na błonicę, tężec i krztusiec wśród dzieci w wieku 1 lat;
  \item HIV\_AIDS -- liczba zgonów spowodowana AIDS na 1000 dzieci do 4 roku życia;
  \item GDP -- produkt krajowy brutto na mieszkańca w dollarach;
  \item population -- populacja danego kraju
  \item thinness\_1\_19\_years -- występowanie szczupłości wśród dzieci i młodzieży w wieku od 10 do 19 lat;
  \item thinness\_5\_9\_years -- występowanie szczupłości wśród dzieci i młodzieży w wieku od 5 do 9 lat;
  \item HDI -- stopień rozwoju społeczno-ekonomicznego poszczególnych krajów;
  \item schooling -- średnia liczba lat spędzonych na nauce w szkołach.
\end{itemize}

Widzimy, że mamy nasz zbiór zawiera bardzo dużo informacji o poszczególnych 183 krajach, pozyskanych w latach 2000--2015, pozwalających okreslić ich aktualny rozwój lub możliwy poziom życia mieszkanców.  W naszym raporcie skorzystamy wyłącznie z oczekiwanej długości życia i średniego czasu edukacji w 2015 roku, czyli najbardziej aktualnych danych. Dla tego roku zawarta jest pełna informacja o 173 krajach.

```{r scatter, fig.cap="\\label{fig:scatter} Wykres punktowy badanych danych.", fig.align="center", fig.width = 4, fig.height = 3}
ggplot() +
  geom_point(aes(X, Y), alpha=0.6, size=1) +
  xlab("Czas nauki") +
  ylab("Długość życia")
```

Na powyższym wykresie widzimy wyraźną zależność liniową pomiędzy dwoma zmiennymi. W dalszej części poddamy ją głębszej analizie.


\section{Statystyki}

Nasze dane składają się z bardzo duzej liczby kolumn Wybraliśmy najważniejsze statystyki takie jak : \textit{life\_expectancy}, \textit{adult\_mortality}, \textit{BMI}, \textit{GDP}, \textit{population}, \textit{HDI}, \textit{schooling} dla których następnie zostały wyliczone podstawowe parametry statystyczne. Wyniki przedstawiliśmy w poniższej \ref{tab:data} tabeli:

 \begin{table}[H]
       \caption{Tabela z parametrami statystycznymi.?}
      \label{tab:data}
      \centering
      \begin{tabular}{|c|c|c|c|c|c|c|c|}
          \hline
           & \textit{life\_expectancy} & \textit{adult\_mortality} &  \textit{BMI} & \textit{GDP} & \textit{population} & \textit{HDI} & \textit{schooling} \\
          \hline
          Minimum & 51.00 & 1.0 & 2.5 & 33.68 & 2966 & 0.3470 & 4.90 \\
          \hline
          1 Kwartyl? & 66.00 & 74.0 & 24.25 & 777.25 &  268071 & 0.5650 & 10.80 \\
          \hline
          Mediana & 73.90 & 138.0 & 49.90 & 2954.12 & 2076086 & 0.7230 & 13.10   \\
          \hline
          Średnia & 71.71 & 151.4 & 42.81 & 7229.50 & 11097408 & 0.6917 & 12.93   \\
          \hline
          3 Kwartyl? & 76.70  & 211.0  & 61.35 & 7388.98  & 9940296  & 0.7980  & 15.00\\
          \hline
          Maksimum & 88.00 & 484.0 & 77.60 & 66346.52 & 258162113 & 0.9480 & 20.40 \\
          \hline
          NA’s & 0 & 0 & 2 & 20 & 31 & 0 & 0 \\
          \hline
  \end{tabular}
\end{table}

Widzimy, że oczekiwana długość życia jest wynosi srednio około 72 lata. Tutaj warto zaznaczyć, ze istnieje dużą dysproporcja, w czynnikach które mają wpływ na ten parametr. Patrząc przykładowo na GDI, widizmy że istnieje spora rozbieżność pomiędzy krajami lub na schooling, gdzie niekiedy eduakcja trwa 5 a czasem 20 lat. Parametry przedstawione w tabeli \ref{tab:data}}  bezpośrednio przekładają się na dłguość życia. W swoim raporcie przyjżymy się korelacji  pomiędzy \textit{schooling}, a \textit{life\_expectancy}.





\section{Regresja}
|      Aby dopasować do danych prostą regresji, skorzystamy z metody najmniejszych kwadratów. Oznaczmy licznę danych (państw) jako $n = 173$. Przyjmijmy model
$$ Y_i = \beta_1 x_i + \beta_0 + \epsilon_i, \ \ \ i = 1, 2, \dots, n $$
gdzie $x_i$ to dane dotyczące czasu nauczania, a $\epsilon_i$ są niezależnymi zmiennymi losowymi ze średnią równą 0 i skończoną wariancją. Oznaczmy dane z czasem życia jako $y_i$ - będziemy traktować je jako realizacje zmiennych losowych $Y_i$. Wspomniana metoda polega na znalezieniu takich współczynników $\beta_1, \beta_0$, dla których funkcja
$$ S(\beta_1, \beta_0) = \sum_{i = 1}^n (y_i - \beta_1 x_i - \beta_0)^2 $$
przyjmuje wartość najmniejszą. Rozwiązaniem jest para estymatorów
$$
    \begin{cases}
      \hat{\beta_1} = R \dfrac{S_y}{S_x} = \dfrac{\sum\limits_{i = 1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sum\limits_{i = 1}^n(x_i - \bar{x})^2}\\
      \hat{\beta_0} = \bar{y} - \hat{\beta_1} \bar{x}
    \end{cases}
$$
gdzie $R$ jest współczynnikiem korelacji Pearsona, a $S_x, S_y$ są próbkowymi odchyleniami standardowymi. Można pokazać, że estymatory te są nieobciążone. Po podstawieniu danych otrzymujemy
$$
    \begin{cases}
      \hat{\beta_1} \approx 2.23 \\
      \hat{\beta_0} \approx 42.9
    \end{cases}.
$$
Wyestymowane wartości $Y_i$ będą miały postać
$$ \hat{y_i} = \hat{\beta_1} x_i + \hat{\beta_0}. $$

```{r regresja, fig.cap="\\label{fig:regresja} Wykres punktowy wraz z prostą regresji wyznaczona dla danych.", fig.align="center", fig.width = 6, fig.height = 3}
ggplot() + 
  geom_point(aes(X, Y, col='a'), size=0.5) + 
  geom_line(aes(X, a*X + b, col='b'), linewidth=0.5) + 
  scale_color_manual(labels=c("Dane", "Prosta regresji"), values=c('#008cff', "#da350b")) +
  labs(col="") +
  xlab("Czas nauki") +
  ylab("Długość życia")
```

Jak możemy zauważyć wyznaczona prosta pokrywa się z danymi. Wspołczynnik determinancji, czyli $R^2$ wyniósł 0.67, a więc jest to dość zadowalające dopasowanie.





\section{Analiza residuów}

|      Aby sprawdzić, czy dane spełniają założenia modelu tj.
\begin{enumerate}
  \item $ \mathrm{E} \epsilon_i = 0 $,
  \item $ \mathrm{Var}(\epsilon_i) < \infty $,
  \item $ \epsilon_i $ są niezależne,
\end{enumerate}
przeprowadzimy analizę residuów (błędów)
$$e_i = y_i - \hat{y_i},$$
czyli realizacji zmiennych $\epsilon_i$. Ponieważ estymatory $\hat{\beta_1}, \hat{\beta_0}$ zostały wyznaczone metodą najmniejszych kwadratów, to pierwsze założenie na pewno jest spełnione. Dodatkowo, jeśli spojrzymy na wykres \ref{fig:res_scatter}, residua wydają się być rozłożone losowo wokół zera.

```{r res_scatter, fig.cap="\\label{fig:res_scatter} Wykres punktowy residuów.", fig.align="center", fig.width = 4, fig.height = 3}
df <- data.frame(X=X, Y=Y, E=E)
df <- df %>% arrange(X)
ggplot() + 
  geom_point(aes(1:length(E), df$E), size=0.5, col="#1b65f9", alpha=0.7) + 
  geom_line(aes(1:length(E), 0), linewidth=0.5) +
  labs(col="") +
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  ylab(TeX("$e_i$"))
```

|      W przypadku założenia drugiego obliczymy wariancje częściowe postaci
$$ S^2_k = \frac{1}{k - 1} \sum_{i=1}^k e_i^2, \ \ \ k = 2, \dots, n. $$

```{r res_wariancja, fig.cap="\\label{fig:res_wariancja} Porównanie wariancji częściowej $S^2_k$ residuów dla $k = 2,... , n$ z wariancją z całej próby, czyli $S^2_n$.", fig.align="center", fig.width = 6, fig.height = 3}
n <- length(E)
varE <- c()
for (i in 2:n) {
    varE <- append(varE, var(E[1:i]))
}
ggplot() + 
  geom_line(aes(2:n, varE, col='a')) + 
  geom_line(aes(2:n, var(E), col='b')) +
  scale_color_manual(labels=c(TeX("$S^2_k$"), TeX("$S^2_n$")), values=c('#00b3ff', "#d36f12")) +
  labs(col="") +
  xlab(TeX("$k$")) +
  ylab("Wariancja")
```

Na powyższym wykresie zobaczyć możemy, że wariancja częściowa wraz ze zwiększającym się $k$ szybko zbiega do wartości wariancji z całej próbki i oscyluje wokół niej. Na tej podstawie możemy zakładać, że $\mathrm{Var}(\epsilon_i)$ jest skończona i stała.

|      Aby zweryfikować, czy spełnione jest założenie trzecie, skorzystamy z funkcji empirycznej autokorelacji o postaci
$$ \hat{\rho}(h) = \dfrac{\hat{\gamma}(h)}{\hat{\gamma}(0)}, $$
gdzie
$$ \hat{\gamma}(h) = \frac{1}{n} \sum_{i=1}^{n - |h|} (e_{i + |h|} - \bar{e}) (e_i - \bar{e}) $$
jest estymatorem funkcji autokowariancji.

```{r res_korelacja, fig.cap="\\label{fig:res_korelacja} Wykres punktowy empirycznej autokorelacji w zależności od przesunięcia $h$.", fig.align="center", fig.width = 4, fig.height = 3}
n <- length(E)
hs <- 0:50
Xt <- rnorm(n, 0, sd(E))

g_ <- function(X, h) {
    return ( mean( (X[(1+h):n] - mean(X)) * (X[1:(n-h)] - mean(X)) ) )
}

g_s <- c()
g_s2 <- c()
for (h in hs) {
    g_s <- append(g_s, g_(E, h))
    g_s2 <- append(g_s2, g_(Xt, h))
}

r_s = g_s / g_(E, 0)
r_s2 = g_s2 / g_(Xt, 0)

ggplot() + 
  geom_point(aes(hs, r_s), size=1) +
  labs(col="") +
  xlab(TeX("$h$")) +
  ylab(TeX('$\\hat{\\rho}(h)$'))
```

Na wykresie \ref{fig:res_korelacja} widać, że dla $h \neq 0$ funkcja $\hat{\rho}(h)$ oscyluje wokół zera, zatem wnioskujemy, że residua są od siebie niezależne.

|      Teraz postaramy się znaleźć rozkład błędów $e_i$. Zaczniemy od spojrzenia na ich histogram (wykres \ref{fig:res_histogram}).

```{r res_histogram, fig.cap="\\label{fig:res_histogram} Histogram residuów.", fig.align="center", fig.width = 4, fig.height = 3}
ggplot() + 
  geom_histogram(aes(x=E, y=..density..), bins=13) +
  xlab(TeX("$e_i$")) +
  ylab(TeX("Gęstość"))
```

Kształt histogramu przypomina nieco rozkład normalny. Załóżmy, że w rzeczywistości tak jest. Wtedy nieobciążonym estymatorem wariancji jest
$$ S^2 = \frac{1}{n - 2} \sum_{i=1}^n e_i^2 \approx 20.93 \ . $$

```{r res_gestosc, fig.cap="\\label{fig:res_gestosc} Porównanie histogramu z danych z gęstością teoretyczną rozkładu $\\mathcal{N}(0, S^2)$.", fig.align="center", fig.width = 6, fig.height = 3}
S <- sum(E^2) / (n - 2)
xs <- seq(min(E), max(E) + 3, 0.01)
ggplot() + 
  geom_histogram(aes(x=E, y=..density.., fill='a'), bins=13) + 
  geom_line(aes(xs, dnorm(xs, 0, sqrt(S)), col='b'), linewidth=1) + 
  scale_color_manual(labels=c("gęstość teoret."), values=c('#f13b3b')) +
  scale_fill_manual(labels=c("histogram"), values=c('#586974')) +
  labs(col="", fill="") +
  xlab(TeX("$e_i$")) +
  ylab("Gęstość")
```

```{r res_dystrybuanta, fig.cap="\\label{fig:res_dystrybuanta} Porównanie dystrybuanty empirycznej z danych z dystrybuantą teoretyczną rozkładu $N(0, S^2)$.", fig.align="center", fig.width = 6, fig.height = 3}
F <- ecdf(E)
xs <- seq(min(E), max(E), 0.01)
ggplot() + 
  geom_line(aes(x=xs, y=F(xs), col='a'), linewidth=0.5) + 
  geom_line(aes(x=xs, y=pnorm(xs, 0, sqrt(S)), col='b'), linewidth=0.5) +
  scale_color_manual(labels=c("Dystrybuanta empir.", "Dystrybuanta teoret."), values=c('#00b3ff', "#d36f12")) +
  labs(col="") +
  xlab(TeX("$e_i$")) +
  ylab("Dystrybuanta")
```

Na wykresie \ref{fig:res_gestosc} zauważamy, że histogram w miarę pokrywa się z gęstoością teoretyczną. Nie spodziewamy się tutaj bardzo dokładnego pokrywania ze względu na niewielką liczbę danych. Z kolei na wykresie \ref{fig:res_dystrybuanta} widzimy, że dystrybuanta empiryczna wyraźnie nakłada się z dystrybuantą teoretyczną. Aby umocnić nasze przekonania co do normalności residuów, przeprowadzimy test Kołmogorowa-Smirnowa. Przedstawmy hipotezy:

\begin{itemize}
\item $\mathcal{H}_0$: wartości residuów są z rozkładu $\mathcal{N}(0, S^2)$
\item $\mathcal{H}_1$: wartości residuów nie są z rozkładu $\mathcal{N}(0, S^2)$
\end{itemize}

Otrzymana p-wartość testu wynosi 0,2532. Ponieważ otrzymany wynik jest wystarczająco duży, to nie mamy podstaw do odrzucenia hipotezy zerowej i możemy przyjąć, że dane pochodzą z rozkładu $\mathcal{N}(0, S^2)$.





\section{Przedziały ufności}

 W celu skostrukcji przedziałów ufności posłużymy się estymatorami $\hat{\beta_0}$ $\hat{\beta_1}$ i ich własnościami:
$$\mathrm{E}\left[\hat{\beta_0} \right] = \hat{\beta_0} \quad \text{oraz} \quad \mathrm{E}\left[\hat{\beta_1} \right] = \hat{\beta_1}$$ 
$$Var(\hat{\beta_0}) = \sigma^2 \left( \frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n \left( x_i - \bar{x} \right)^2} \right)$$

$$Var(\hat{\beta_1}) = \frac{\sigma^2}{\sum_{i=1}^n \left( x_i - \bar{x} \right)^2}$$
oraz wiemy, że 

$$ \epsilon_i  \sim \mathcal{N}(0,\,\sigma^{2})\,. $$

$$ \hat{\beta_0} \sim \mathcal{N}(\mathrm{E}\left[\hat{\beta_0} \right],\,Var[\hat{\beta_0}])\,. $$

$$ \hat{\beta_1} \sim \mathcal{N}(\mathrm{E}\left[\hat{\beta_1} \right],\,Var[\hat{\beta_1}])\,. $$
Na podstawie powyższych informacji tworzymy przedziały ufności dla estymatorów $\hat{\beta_0}$ $\hat{\beta_1}$, uwzględniajać ze parametr $\sigma$ jest nieznany.

$$ \mathcal{P} \left(\hat{\beta_0} < z_2 \right) =  1 - \frac{\alpha}{2}$$
$$ \mathcal{P} \left( -z_2 < \hat{\beta_0} < z_2 \right) =  1 - \alpha$$
$$ \mathcal{P} \left( -z_2 < \frac{\hat{\beta_0} - \beta_0}{S\sqrt{\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2}}} < z_2 \right) =  1 - \frac{\alpha}{2}$$
$$ \mathcal{P} \left( \hat{\beta_0} -z_2S\sqrt{\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2}} < \beta_0 < \hat{\beta_0} + z_2S\sqrt{\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2}} \right) =  1 - \frac{\alpha}{2}$$
Otrzymaliśmy przedział ufności dla parametru $\beta_0$, gdzie $z_2$ jest kwantylem pochodzącym z rozkładu $t$-studenta z $n-2$ stopniami swobody. Analogicznie wyliczamy przedział ufności dla parametru $\beta_1$. Wygląda on następująco:

$$ \mathcal{P} \left( \hat{\beta_1} -z_2S\sqrt{\frac{1}{\sum_{i=1}^n (x_i - \bar{x})^2}} < \beta_1 < \hat{\beta_1} + z_2S\sqrt{ \frac{1}{\sum_{i=1}^n (x_i - \bar{x})^2}} \right) =  1 - \frac{\alpha}{2}$$

Dla otrzymanych przedziałow ufności ... dociągnać plus wykresy
\section{Predykcja}

