---
title: "Komputerowa analiza szeregów czasowych - raport 1"
author: "Szymon Malec, Tomasz Hałas"
output:
  pdf_document: 
    extra_dependencies: ["polski", "mathtools", "amsthm", "amssymb", "icomma", "upgreek", "xfrac", "scrextend", "float", "tabularx", "hyperref", "caption", "enumitem"]
fontsize: 12pt
---

\renewcommand{\figurename}{Wykres}
\renewcommand{\tablename}{Tablica}
\raggedbottom

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE, fig.pos = "H")
```

```{r}
library(ggplot2)
library(dplyr)
library(zeallot)
library(tidyr)
library(knitr)
library(reshape2)
library(cowplot)

data <- read.csv("data/data.csv")
data2015 <- data %>% filter(year == 2015)


regression <- function(X, Y, xlabel="", ylabel="", display_plot=TRUE){
    r <- cor(X, Y, use="pairwise.complete.obs")
    Sx <- sd(X)
    Sy <- sd(Y)
    a <- r * Sy / Sx
    b <- mean(Y) - a * mean(X)

    if(display_plot){
        xs <- seq(min(X), max(X), 0.01)
        plt <- ggplot() +
            geom_point(aes(x=X, y=Y), alpha=0.5) +
            geom_line(aes(x = xs, y = a * xs + b), linewidth=1, col="red") +
            xlab(xlabel) + 
            ylab(ylabel)
        show(plt)
    }
    else{
      return(c(a, b))
    }
}
```




\section{Wstęp}
<!-- Akapit - 6 spacji -->
|      Celem raportu jest ...



\section{Opis danych}



\section{Regresja}
|      Jako pierwszy przeanalizujemy wpływ czasu edukacji na oczekiwaną długość życia. W tym przypadku rozważymy dane wyłącznie z 2015 roku, czyli te najbardziej aktualne. Na wykresie \ref{fig:scatter_schooling} można zauważyć liniową zależność danych, zatem do zbadania korelacji możemy użyć współczynnika Pearsona. Przyjmuje on wartość $R \approx 0,752$, więc jest to dość mocna korelacja. Dopasujemy teraz do danych prostą regresji korzystając z metody najmniejszych kwadratów. Przyjmijmy model
$$ Y_i = ax_i + b + \epsilon_i, $$
gdzie $x_i$ to dane dotyczące czasu nauczania, a $\epsilon_i$ są i.i.d. ze średnią równą 0 i skończoną wariancją. Oznaczmy dane z czasem życia jako $y_i$. Wspomniana metoda polega na znalezieniu takich współczynników $a, b$ dla których funkcja
$$S(a,b) = \sum_{i = 1}^n (y_i - ax_i - b)^2$$
przyjmuje wartość najmniejszą. Rozwiązaniem jest para estymatorów
$$
    \begin{cases}
      \hat{a} = R\frac{S_y}{S_x} = \frac{\sum_{i = 1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^n(x_i - \bar{x})^2}\\
      \hat{b} = \bar{y} - a\bar{x}
    \end{cases}
$$
gdzie $R$ jest współczynnikiem korelacji Pearsona, a $S_x, S_y$ są próbkowymi odchyleniami standardowymi.

```{r scatter_schooling, fig.cap="\\label{fig:scatter_schooling} Prosta regresji wyznaczona dla danych.", fig.align="center", fig.width = 4, fig.height = 3}

df <- data[(!is.na(data$schooling)) & (!is.na(data$life_expectancy)) & (data$year == 2015),]
regression(df$schooling, df$life_expectancy, "Lata nauki", "Długość życia")
```


Kolejnym punktem będzie analiza residuów (błędów)
$$e_i = y_i - \hat{y}_i\;,$$
gdzie $\hat{y}_i = \hat{a}x_i + \hat{b}$. W celu zbadania rozkładu residuów, spójrzmy na ich histogram

```{r hist_schooling, fig.cap="\\label{fig:hist_schooling} Histogram residuów.", fig.align="center", fig.width = 4, fig.height = 3}
ab <- regression(df$schooling, df$life_expectancy, display_plot = FALSE)
a <- ab[1]
b <- ab[2]
e <- df$life_expectancy - a*df$schooling - b
ggplot(data.frame(e = e), aes(e)) + 
  geom_histogram(aes(y = after_stat(density)), fill = 'white', color = 'black') + 
  xlab("Wartość błędu") +
  theme(axis.title.y = element_blank())
```

Kształt histogramu jest zbliżony do krzywej gaussowskiej. Średnia wartość residuów wynosi $\mu_e = 0$, a ich wariancja $\sigma_e^2 = 20,81$. Posłużymy się testem Kołmogorowa-Smirnova w celu zbadania normalności rozkładu błędów. Przedstawmy hipotezy:

\begin{itemize}
\item $\mathcal{H}_0$: wartości residuów są z rozkładu normalnego $\mathcal{N}(0, 20.81)$
\item $\mathcal{H}_1$: wartości residuów nie są z rozkładu normalnego $\mathcal{N}(0, 20.81)$
\end{itemize}

```{r, echo = FALSE, eval = FALSE}
ks.test(e, 'pnorm', 0, sd(e))
```

Wyznaczona p-wartość wynosi $p = 0,2532$. Ponieważ otrzymany wynik jest wystarczająco duży, to nie mamy podstaw do odrzucenia hipotezy zerowej i możemy przyjąć, że dane pochodzą z rozkładu normalnego $\mathcal{N}(0, 20.81)$. 

|      Analiza residuów jest niezwykle istotna, kiedy decydujemy się robić predykcję danych. Znając rozkład błędów, możemy wyznaczyć przedziały ufności o danym poziomie istotności dla przewidywanych wyników. Innymi słowy możemy wyznaczyć prawdopodobieństwo z jakim predykowana wartość zmieści się w konkretnym przedziale. Wyniki, które otrzymaliśmy mogą być podstawą do wykonania takiej predykcji, jednak wcześniej należałoby jeszcze sprawdzić, czy residua są od siebie niezależne oraz czy ich wariancja jest stała.





\section{Analiza residuów}






# 7. PKB państwa, a długość życia

|      Podobnie jak w przypadku długości edukacji, będziemy analizować dane dotyczące PKB wyłącznie z 2015 roku. W przeciwieństwie do poprzedniego przypadku, dane te nie są zależne liniowo. Ich wykres punktowy kształtem przypomina bardziej zależność logarytmiczną. Sprawdźmy zatem, czy w rzeczywistości tak jest nakładając logarytm na wartości PKB.

```{r scatter_gdp_line, fig.cap="\\label{fig:scatter_gdp_line} Wykresy punktowe z surowych danych po lewej i z przetransformowanych po prawej.", fig.align="center", fig.width = 6, fig.height = 2}
df2 <- data[(!is.na(data$GDP)) & (!is.na(data$life_expectancy)) & (data$year == 2015),]
scat2 <- ggplot(data = df2, mapping = aes(x = GDP, y = life_expectancy)) + geom_point(alpha=0.5) + 
  xlab("PKB") +
  ylab("Długość życia")
scat2_mod <- ggplot(data = df2, mapping = aes(x = log(GDP), y = life_expectancy)) + geom_point(alpha=0.5) +
  xlab("log(PKB)") +
  theme(axis.title.y = element_blank())
plot_grid(scat2, scat2_mod)
```

Możemy zauważyć, że dane po transformacji przypominają bardziej zależne liniowo, choć są dość mocno rozrzucone. Współczynnik korelacji Pearsona dla przetransformowanych danych wynosi 0.52. Przyjmnijmy model
$$ Y_i = a\log(x_i) + b + \epsilon_i, $$
gdzie $x_i$ są danymi z PKB, a $\epsilon_i$ są i.i.d. o średniej równej 0 i skończonej wariancji. Aby jednak otrzymać model lioniowy jak w punkcie 6, podstawiamy $z_i = \log(x_i)$ i otrzymujemy
$$ Y_i = az_i + b + \epsilon_i. $$
Teraz już możemy skorzystać z metody najmniejszych kwadratów, aby dopasować prostą regresji. W ten sposób otrzymujemy estymatory postaci
$$
    \begin{cases}
      \hat{a} = \frac{\sum_{i = 1}^n(z_i - \bar{z})(y_i - \bar{y})}{\sum_{i = 1}^n(z_i - \bar{z})^2} \\
      \hat{b} = \bar{y} - a\bar{z}
    \end{cases}
$$

```{r reg_gdp_final, fig.cap="\\label{fig:reg_gdp_final} Po lewej prosta regresji dla przetransformowanych danych. Po prawej krzywa regresji dopasowana do oryginalnych danych.", fig.align="center", fig.width =6, fig.height = 2}
c(a1, b1) %<-% regression(log(df2$GDP), df2$life_expectancy, display_plot=FALSE)
xs1 <- seq(min(log(df2$GDP)), max(log(df2$GDP)), 0.1)
reg2 <- ggplot() + geom_point(aes(log(df2$GDP), df2$life_expectancy), alpha = 0.5) + 
  geom_line(aes(xs1, a1*xs1 + b1), col='red', linewidth=1) +
  xlab("log(PKB)") +
  ylab("Długość życia")

c(a2, b2) %<-% regression(log(df2$GDP), df2$life_expectancy, display_plot=FALSE)
xs2 <- seq(0.1, max(df2$GDP), 10)
reg2_final <- ggplot() + geom_point(aes(df2$GDP, df2$life_expectancy), alpha = 0.5) + 
  geom_line(aes(xs2, a2*log(xs2) + b2), col='red', linewidth=1) +
  xlab("PKB") +
  theme(axis.title.y = element_blank())

plot_grid(reg2, reg2_final)
```

Jak możemy zobaczyć, krzywa logarytmiczna w miarę pokrywa się z danymi, więc można przyjać ją za przybliżenie zależności pomiędzy dwoma zmiennymi. Ważną obserwacją jest to, że największy wzrost mamy dla bardzo małych wartości PKB - im jest większe, tym wolniej rośnie długość życia. Oznacza to, że dla państw z małym PKB, nawet niewielki jego wzrost może przyczynić się do znacznego zwiększenia długości życia, zaś dla państw lepiej rozwinietych, wzrost PKB ma już na to nieznaczny wpływ.
